{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n",
      "Keras version:  2.2.4-tf\n",
      "Tensorboard version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorboard\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('TensorFlow version: ', tf.__version__)\n",
    "print('Keras version: ', keras.__version__)\n",
    "print('Tensorboard version:', tensorboard.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99988\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>dist</th>\n",
       "      <th>gender</th>\n",
       "      <th>make</th>\n",
       "      <th>year</th>\n",
       "      <th>new_used</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Norfolk County</td>\n",
       "      <td>0.66988</td>\n",
       "      <td>f</td>\n",
       "      <td>toyota</td>\n",
       "      <td>0.990594</td>\n",
       "      <td>used</td>\n",
       "      <td>410.040033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>Kelowna</td>\n",
       "      <td>0.75080</td>\n",
       "      <td>f</td>\n",
       "      <td>acura</td>\n",
       "      <td>0.992574</td>\n",
       "      <td>used</td>\n",
       "      <td>431.022626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.41</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>0.91720</td>\n",
       "      <td>f</td>\n",
       "      <td>honda</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>used</td>\n",
       "      <td>410.040033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Gatineau</td>\n",
       "      <td>0.77396</td>\n",
       "      <td>f</td>\n",
       "      <td>acura</td>\n",
       "      <td>0.997030</td>\n",
       "      <td>used</td>\n",
       "      <td>421.946006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Blainville</td>\n",
       "      <td>0.77136</td>\n",
       "      <td>m</td>\n",
       "      <td>chevy</td>\n",
       "      <td>0.993069</td>\n",
       "      <td>used</td>\n",
       "      <td>720.832348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>0.83</td>\n",
       "      <td>Delta</td>\n",
       "      <td>0.34192</td>\n",
       "      <td>m</td>\n",
       "      <td>chevy</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>used</td>\n",
       "      <td>720.832348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19996</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Red Deer</td>\n",
       "      <td>0.59248</td>\n",
       "      <td>f</td>\n",
       "      <td>nissan</td>\n",
       "      <td>0.999505</td>\n",
       "      <td>new</td>\n",
       "      <td>410.040033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19997</td>\n",
       "      <td>0.27</td>\n",
       "      <td>Longueuil</td>\n",
       "      <td>0.52980</td>\n",
       "      <td>f</td>\n",
       "      <td>ford</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>used</td>\n",
       "      <td>1744.513412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19998</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>0.90784</td>\n",
       "      <td>m</td>\n",
       "      <td>mercedes</td>\n",
       "      <td>0.992574</td>\n",
       "      <td>used</td>\n",
       "      <td>773.543820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19999</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Saint Catharines</td>\n",
       "      <td>0.70944</td>\n",
       "      <td>m</td>\n",
       "      <td>gmc</td>\n",
       "      <td>0.991584</td>\n",
       "      <td>used</td>\n",
       "      <td>729.908968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age              city     dist gender      make      year new_used  \\\n",
       "0      0.76    Norfolk County  0.66988      f    toyota  0.990594     used   \n",
       "1      0.62           Kelowna  0.75080      f     acura  0.992574     used   \n",
       "2      0.41       Quebec City  0.91720      f     honda  0.995050     used   \n",
       "3      0.80          Gatineau  0.77396      f     acura  0.997030     used   \n",
       "4      0.80        Blainville  0.77136      m     chevy  0.993069     used   \n",
       "...     ...               ...      ...    ...       ...       ...      ...   \n",
       "19995  0.83             Delta  0.34192      m     chevy  0.999010     used   \n",
       "19996  0.79          Red Deer  0.59248      f    nissan  0.999505      new   \n",
       "19997  0.27         Longueuil  0.52980      f      ford  0.990099     used   \n",
       "19998  0.71           Calgary  0.90784      m  mercedes  0.992574     used   \n",
       "19999  0.56  Saint Catharines  0.70944      m       gmc  0.991584     used   \n",
       "\n",
       "             quote  \n",
       "0       410.040033  \n",
       "1       431.022626  \n",
       "2       410.040033  \n",
       "3       421.946006  \n",
       "4       720.832348  \n",
       "...            ...  \n",
       "19995   720.832348  \n",
       "19996   410.040033  \n",
       "19997  1744.513412  \n",
       "19998   773.543820  \n",
       "19999   729.908968  \n",
       "\n",
       "[20000 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_path / file_csv[0],)\n",
    "df = df.drop(['model'],axis=1,inplace=False)\n",
    "df['age'] = df['age']/100.0\n",
    "df['dist'] = df['dist']/25000.0\n",
    "df['year'] = df['year']/2020.0\n",
    "print(df['dist'].max())\n",
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_1.csv\n",
      "(20000,)\n",
      "(20000, 1, 114)\n",
      "(20000,)\n",
      "['company_1.csv']\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('/home/tim/Documents/flask_experiment/data')\n",
    "\n",
    "# file_csv = []\n",
    "# index_count = 0\n",
    "# for file in os.listdir(data_path):\n",
    "#     # open up the .mat file\n",
    "#     if file.endswith(\".csv\"):\n",
    "#         file_csv.append(file)\n",
    "#         print(file)\n",
    "#         df = pd.read_csv(data_path / file,)\n",
    "#         # scale some of the large values\n",
    "#         df['age'] = df['age']/100.0\n",
    "#         df['dist'] = df['dist']/25000.0\n",
    "#         df['year'] = df['year']/2020.0\n",
    "#         df = df.drop(['model'],axis=1,inplace=False)\n",
    "#         if index_count == 0:\n",
    "#             y = df['quote'].to_numpy()\n",
    "#             df = df.drop(['quote'],axis=1,inplace=False)\n",
    "#             df = pd.get_dummies(df,drop_first=True)\n",
    "#             X = df.to_numpy()\n",
    "#             index_count += 1\n",
    "#         else:\n",
    "#             a = df['quote'].to_numpy()\n",
    "#             y = np.vstack((a, y))\n",
    "#             df = df.drop(['quote'],axis=1,inplace=False)\n",
    "#             df = pd.get_dummies(df,drop_first=True)\n",
    "#             X = np.dstack((df.to_numpy(), X))\n",
    "#             index_count += 1\n",
    "\n",
    "# y = np.reshape(y,(-1))\n",
    "# X = np.reshape(X,(X.shape[0],X.shape[1],-1))\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(file_csv)\n",
    "\n",
    "\n",
    "file_csv = []\n",
    "index_count = 0\n",
    "for file in os.listdir(data_path):\n",
    "    # open up the .mat file\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_csv.append(file)\n",
    "        print(file)\n",
    "        df = pd.read_csv(data_path / file,)\n",
    "        # scale some of the large values\n",
    "        df['age'] = df['age']/100.0\n",
    "        df['dist'] = df['dist']/25000.0\n",
    "        df['year'] = df['year']/2020.0\n",
    "        df = df.drop(['model'],axis=1,inplace=False)\n",
    "        if index_count == 0:\n",
    "            y = df['quote'].to_numpy()\n",
    "            print(y.shape)\n",
    "            df = df.drop(['quote'],axis=1,inplace=False)\n",
    "            df = pd.get_dummies(df,drop_first=True)\n",
    "            X = df.to_numpy()\n",
    "            index_count += 1\n",
    "        else:\n",
    "            a = df['quote'].to_numpy()\n",
    "            y = np.vstack((a, y))\n",
    "            df = df.drop(['quote'],axis=1,inplace=False)\n",
    "            df = pd.get_dummies(df,drop_first=True)\n",
    "            X = np.dstack((df.to_numpy(), X))\n",
    "            index_count += 1\n",
    "\n",
    "X = np.reshape(X,(X.shape[0],-1,X.shape[1]))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(file_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 114)\n",
      "(10000,)\n",
      "(10000, 1, 114)\n",
      "(10000,)\n",
      "X_train_q shape: (4489, 1, 114) \ty_train_q shape: (4489,)\n",
      "X_val_q: (2211, 1, 114) \t\t\ty_val_q shape: (2211,)\n",
      "X_test_q: (3300, 1, 114) \t\ty_test_q shape: (3300,)\n"
     ]
    }
   ],
   "source": [
    "# split up the X and y for both the confidence interval and \n",
    "X_quote = X[0:int(X.shape[0]/2)]\n",
    "y_quote = y[0:int(y.shape[0]/2)]\n",
    "print(X_quote.shape)\n",
    "print(y_quote.shape)\n",
    "X_conf = X[int(X.shape[0]/2):]\n",
    "y_conf = y[int(y.shape[0]/2):]\n",
    "print(X_conf.shape)\n",
    "print(y_conf.shape)\n",
    "\n",
    "X_train_q, X_test_q, y_train_q, y_test_q = train_test_split(X_quote, y_quote, test_size=0.33, random_state=42)\n",
    "X_train_q, X_val_q, y_train_q, y_val_q = train_test_split(X_train_q, y_train_q, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"X_train_q shape:\", X_train_q.shape, \"\\ty_train_q shape:\", y_train_q.shape)\n",
    "print(\"X_val_q:\", X_val_q.shape, \"\\t\\t\\ty_val_q shape:\", y_val_q.shape)\n",
    "print(\"X_test_q:\", X_test_q.shape, \"\\t\\ty_test_q shape:\", y_test_q.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(200, activation=\"relu\", input_shape=[1, 114]),\n",
    "    keras.layers.Dense(200, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 1, 200)            23000     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 200)            40200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 50)             10050     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 1)              51        \n",
      "=================================================================\n",
      "Total params: 73,301\n",
      "Trainable params: 73,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"mse\"])\n",
    "\n",
    "# create a name for the model so that we can track it in tensorboard\n",
    "log_dir=\"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"_quote\"\n",
    "\n",
    "# create tensorboard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0,\n",
    "                                                      update_freq='epoch',profile_batch=0)\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"mse\",\n",
    "        patience=1000,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4489 samples, validate on 2211 samples\n",
      "Epoch 1/10000\n",
      "4489/4489 [==============================] - 1s 248us/sample - loss: 13987.2987 - mse: 13987.2910 - val_loss: 2436.4410 - val_mse: 2436.4414\n",
      "Epoch 2/10000\n",
      "4489/4489 [==============================] - 1s 112us/sample - loss: 1225.4847 - mse: 1225.4843 - val_loss: 799.0053 - val_mse: 799.0054\n",
      "Epoch 3/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 757.2209 - mse: 757.2207 - val_loss: 689.8092 - val_mse: 689.8092\n",
      "Epoch 4/10000\n",
      "4489/4489 [==============================] - 1s 119us/sample - loss: 667.6405 - mse: 667.6404 - val_loss: 659.7022 - val_mse: 659.7022\n",
      "Epoch 5/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 617.5228 - mse: 617.5228 - val_loss: 610.8512 - val_mse: 610.8513\n",
      "Epoch 6/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 542.5860 - mse: 542.5861 - val_loss: 568.6434 - val_mse: 568.6434\n",
      "Epoch 7/10000\n",
      "4489/4489 [==============================] - 1s 112us/sample - loss: 466.5944 - mse: 466.5945 - val_loss: 469.8509 - val_mse: 469.8509\n",
      "Epoch 8/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 370.6001 - mse: 370.6001 - val_loss: 375.6318 - val_mse: 375.6318\n",
      "Epoch 9/10000\n",
      "4489/4489 [==============================] - 0s 106us/sample - loss: 282.3939 - mse: 282.3938 - val_loss: 308.0642 - val_mse: 308.0643\n",
      "Epoch 10/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 218.9972 - mse: 218.9972 - val_loss: 256.2638 - val_mse: 256.2637\n",
      "Epoch 11/10000\n",
      "4489/4489 [==============================] - 1s 116us/sample - loss: 183.8652 - mse: 183.8653 - val_loss: 233.6547 - val_mse: 233.6547\n",
      "Epoch 12/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 169.5676 - mse: 169.5676 - val_loss: 228.5772 - val_mse: 228.5771\n",
      "Epoch 13/10000\n",
      "4489/4489 [==============================] - 1s 145us/sample - loss: 156.2087 - mse: 156.2087 - val_loss: 224.2767 - val_mse: 224.2767\n",
      "Epoch 14/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 157.1406 - mse: 157.1406 - val_loss: 208.5649 - val_mse: 208.5649\n",
      "Epoch 15/10000\n",
      "4489/4489 [==============================] - 0s 107us/sample - loss: 149.7447 - mse: 149.7447 - val_loss: 210.8444 - val_mse: 210.8443\n",
      "Epoch 16/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 141.6115 - mse: 141.6115 - val_loss: 217.1633 - val_mse: 217.1633\n",
      "Epoch 17/10000\n",
      "4489/4489 [==============================] - 0s 107us/sample - loss: 134.4213 - mse: 134.4213 - val_loss: 214.9979 - val_mse: 214.9979\n",
      "Epoch 18/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 124.1465 - mse: 124.1465 - val_loss: 209.6438 - val_mse: 209.6438\n",
      "Epoch 19/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 124.2302 - mse: 124.2303 - val_loss: 253.4072 - val_mse: 253.4072\n",
      "Epoch 20/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 121.6084 - mse: 121.6084 - val_loss: 213.8136 - val_mse: 213.8135\n",
      "Epoch 21/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 121.9252 - mse: 121.9252 - val_loss: 216.5222 - val_mse: 216.5222\n",
      "Epoch 22/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 114.1319 - mse: 114.1319 - val_loss: 228.5532 - val_mse: 228.5532\n",
      "Epoch 23/10000\n",
      "4489/4489 [==============================] - 0s 106us/sample - loss: 111.9948 - mse: 111.9948 - val_loss: 216.8678 - val_mse: 216.8678\n",
      "Epoch 24/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 105.5215 - mse: 105.5215 - val_loss: 246.0297 - val_mse: 246.0296\n",
      "Epoch 25/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 104.4290 - mse: 104.4290 - val_loss: 217.3675 - val_mse: 217.3676\n",
      "Epoch 26/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 107.6356 - mse: 107.6356 - val_loss: 233.4416 - val_mse: 233.4416\n",
      "Epoch 27/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 100.2059 - mse: 100.2059 - val_loss: 218.4977 - val_mse: 218.4977\n",
      "Epoch 28/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 91.9884 - mse: 91.9884 - val_loss: 221.5045 - val_mse: 221.5045\n",
      "Epoch 29/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 91.0019 - mse: 91.0019 - val_loss: 224.6010 - val_mse: 224.6010\n",
      "Epoch 30/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 84.3865 - mse: 84.3865 - val_loss: 216.8244 - val_mse: 216.8244\n",
      "Epoch 31/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 85.2338 - mse: 85.2338 - val_loss: 228.3000 - val_mse: 228.3000\n",
      "Epoch 32/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 83.0200 - mse: 83.0200 - val_loss: 227.8633 - val_mse: 227.8633\n",
      "Epoch 33/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 79.2554 - mse: 79.2554 - val_loss: 222.2107 - val_mse: 222.2107\n",
      "Epoch 34/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 85.0421 - mse: 85.0421 - val_loss: 232.1780 - val_mse: 232.1781\n",
      "Epoch 35/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 74.4141 - mse: 74.4142 - val_loss: 240.0817 - val_mse: 240.0816\n",
      "Epoch 36/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 69.5786 - mse: 69.5786 - val_loss: 220.4833 - val_mse: 220.4833\n",
      "Epoch 37/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 71.6448 - mse: 71.6448 - val_loss: 226.8798 - val_mse: 226.8798\n",
      "Epoch 38/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 66.2694 - mse: 66.2694 - val_loss: 234.1962 - val_mse: 234.1963\n",
      "Epoch 39/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 65.2084 - mse: 65.2084 - val_loss: 230.1316 - val_mse: 230.1317\n",
      "Epoch 40/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 57.5594 - mse: 57.5594 - val_loss: 213.4733 - val_mse: 213.4733\n",
      "Epoch 41/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 58.9077 - mse: 58.9077 - val_loss: 219.9674 - val_mse: 219.9674\n",
      "Epoch 42/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 55.9404 - mse: 55.9404 - val_loss: 215.4375 - val_mse: 215.4376\n",
      "Epoch 43/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 52.8563 - mse: 52.8563 - val_loss: 212.5099 - val_mse: 212.5099\n",
      "Epoch 44/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 47.4487 - mse: 47.4487 - val_loss: 207.8898 - val_mse: 207.8899\n",
      "Epoch 45/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 48.6138 - mse: 48.6138 - val_loss: 217.4667 - val_mse: 217.4667\n",
      "Epoch 46/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 47.4639 - mse: 47.4639 - val_loss: 222.6309 - val_mse: 222.6309\n",
      "Epoch 47/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 45.0106 - mse: 45.0106 - val_loss: 211.4818 - val_mse: 211.4818\n",
      "Epoch 48/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 42.2523 - mse: 42.2523 - val_loss: 204.3024 - val_mse: 204.3024\n",
      "Epoch 49/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 39.9294 - mse: 39.9294 - val_loss: 200.0020 - val_mse: 200.0020\n",
      "Epoch 50/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 40.8199 - mse: 40.8199 - val_loss: 197.4877 - val_mse: 197.4877\n",
      "Epoch 51/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 35.4796 - mse: 35.4796 - val_loss: 197.4438 - val_mse: 197.4438\n",
      "Epoch 52/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 43.6893 - mse: 43.6893 - val_loss: 208.8157 - val_mse: 208.8157\n",
      "Epoch 53/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 36.0719 - mse: 36.0719 - val_loss: 195.5204 - val_mse: 195.5204\n",
      "Epoch 54/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 30.8437 - mse: 30.8437 - val_loss: 196.0928 - val_mse: 196.0928\n",
      "Epoch 55/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 32.1657 - mse: 32.1657 - val_loss: 185.0656 - val_mse: 185.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 33.8660 - mse: 33.8660 - val_loss: 197.9223 - val_mse: 197.9223\n",
      "Epoch 57/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 33.1663 - mse: 33.1663 - val_loss: 200.4644 - val_mse: 200.4644\n",
      "Epoch 58/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 28.1669 - mse: 28.1669 - val_loss: 184.9489 - val_mse: 184.9489\n",
      "Epoch 59/10000\n",
      "4489/4489 [==============================] - 0s 106us/sample - loss: 26.9050 - mse: 26.9050 - val_loss: 175.5799 - val_mse: 175.5800\n",
      "Epoch 60/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 25.3985 - mse: 25.3985 - val_loss: 180.4669 - val_mse: 180.4669\n",
      "Epoch 61/10000\n",
      "4489/4489 [==============================] - 1s 125us/sample - loss: 25.8575 - mse: 25.8575 - val_loss: 195.8269 - val_mse: 195.8269\n",
      "Epoch 62/10000\n",
      "4489/4489 [==============================] - 1s 112us/sample - loss: 24.0205 - mse: 24.0205 - val_loss: 183.1305 - val_mse: 183.1305\n",
      "Epoch 63/10000\n",
      "4489/4489 [==============================] - 1s 113us/sample - loss: 25.3913 - mse: 25.3913 - val_loss: 176.9193 - val_mse: 176.9193\n",
      "Epoch 64/10000\n",
      "4489/4489 [==============================] - 1s 112us/sample - loss: 27.2228 - mse: 27.2228 - val_loss: 170.4092 - val_mse: 170.4091\n",
      "Epoch 65/10000\n",
      "4489/4489 [==============================] - 1s 117us/sample - loss: 23.1487 - mse: 23.1487 - val_loss: 186.5125 - val_mse: 186.5125\n",
      "Epoch 66/10000\n",
      "4489/4489 [==============================] - 0s 107us/sample - loss: 22.9716 - mse: 22.9716 - val_loss: 170.2950 - val_mse: 170.2950\n",
      "Epoch 67/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 22.7124 - mse: 22.7124 - val_loss: 181.4554 - val_mse: 181.4554\n",
      "Epoch 68/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 24.7493 - mse: 24.7493 - val_loss: 166.5691 - val_mse: 166.5691\n",
      "Epoch 69/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 19.9927 - mse: 19.9927 - val_loss: 177.3929 - val_mse: 177.3929\n",
      "Epoch 70/10000\n",
      "4489/4489 [==============================] - 0s 107us/sample - loss: 20.1782 - mse: 20.1782 - val_loss: 163.7470 - val_mse: 163.7470\n",
      "Epoch 71/10000\n",
      "4489/4489 [==============================] - 1s 124us/sample - loss: 28.5003 - mse: 28.5003 - val_loss: 179.4919 - val_mse: 179.4919\n",
      "Epoch 72/10000\n",
      "4489/4489 [==============================] - 0s 97us/sample - loss: 22.4570 - mse: 22.4570 - val_loss: 174.2107 - val_mse: 174.2106\n",
      "Epoch 73/10000\n",
      "4489/4489 [==============================] - 1s 111us/sample - loss: 18.0832 - mse: 18.0832 - val_loss: 153.8686 - val_mse: 153.8686\n",
      "Epoch 74/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 20.6274 - mse: 20.6274 - val_loss: 157.0571 - val_mse: 157.0571\n",
      "Epoch 75/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 18.6070 - mse: 18.6070 - val_loss: 157.2668 - val_mse: 157.2668\n",
      "Epoch 76/10000\n",
      "4489/4489 [==============================] - 1s 122us/sample - loss: 18.6445 - mse: 18.6445 - val_loss: 160.4072 - val_mse: 160.4072\n",
      "Epoch 77/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 17.4712 - mse: 17.4712 - val_loss: 157.6382 - val_mse: 157.6382\n",
      "Epoch 78/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 20.1946 - mse: 20.1946 - val_loss: 168.8859 - val_mse: 168.8859\n",
      "Epoch 79/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 18.3848 - mse: 18.3848 - val_loss: 163.6513 - val_mse: 163.6513\n",
      "Epoch 80/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 21.1658 - mse: 21.1658 - val_loss: 157.1268 - val_mse: 157.1268\n",
      "Epoch 81/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 19.0379 - mse: 19.0379 - val_loss: 164.2206 - val_mse: 164.2206\n",
      "Epoch 82/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 20.0320 - mse: 20.0320 - val_loss: 158.1817 - val_mse: 158.1817\n",
      "Epoch 83/10000\n",
      "4489/4489 [==============================] - 1s 117us/sample - loss: 15.3202 - mse: 15.3202 - val_loss: 174.7122 - val_mse: 174.7122\n",
      "Epoch 84/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 17.0668 - mse: 17.0668 - val_loss: 192.7944 - val_mse: 192.7944\n",
      "Epoch 85/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 19.1749 - mse: 19.1749 - val_loss: 179.4976 - val_mse: 179.4975\n",
      "Epoch 86/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 16.3596 - mse: 16.3596 - val_loss: 171.1652 - val_mse: 171.1652\n",
      "Epoch 87/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 16.9796 - mse: 16.9796 - val_loss: 161.6272 - val_mse: 161.6272\n",
      "Epoch 88/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 18.1091 - mse: 18.1091 - val_loss: 157.4140 - val_mse: 157.4140\n",
      "Epoch 89/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 19.9716 - mse: 19.9716 - val_loss: 163.2934 - val_mse: 163.2934\n",
      "Epoch 90/10000\n",
      "4489/4489 [==============================] - 0s 97us/sample - loss: 13.8407 - mse: 13.8407 - val_loss: 147.0665 - val_mse: 147.0665\n",
      "Epoch 91/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 15.4039 - mse: 15.4039 - val_loss: 164.5876 - val_mse: 164.5876\n",
      "Epoch 92/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 15.8779 - mse: 15.8779 - val_loss: 173.5650 - val_mse: 173.5650\n",
      "Epoch 93/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 15.7708 - mse: 15.7708 - val_loss: 158.3851 - val_mse: 158.3851\n",
      "Epoch 94/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 15.9794 - mse: 15.9794 - val_loss: 168.1682 - val_mse: 168.1682\n",
      "Epoch 95/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 12.2192 - mse: 12.2192 - val_loss: 160.1924 - val_mse: 160.1924\n",
      "Epoch 96/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 16.0196 - mse: 16.0196 - val_loss: 150.2027 - val_mse: 150.2027\n",
      "Epoch 97/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 11.0736 - mse: 11.0736 - val_loss: 158.9418 - val_mse: 158.9417\n",
      "Epoch 98/10000\n",
      "4489/4489 [==============================] - 1s 113us/sample - loss: 15.1342 - mse: 15.1342 - val_loss: 156.6666 - val_mse: 156.6667\n",
      "Epoch 99/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 13.8283 - mse: 13.8283 - val_loss: 170.0094 - val_mse: 170.0094\n",
      "Epoch 100/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 12.6032 - mse: 12.6032 - val_loss: 160.5008 - val_mse: 160.5008\n",
      "Epoch 101/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 13.3029 - mse: 13.3029 - val_loss: 153.7693 - val_mse: 153.7693\n",
      "Epoch 102/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 15.3519 - mse: 15.3519 - val_loss: 145.5189 - val_mse: 145.5189\n",
      "Epoch 103/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 16.0975 - mse: 16.0975 - val_loss: 161.9061 - val_mse: 161.9061\n",
      "Epoch 104/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 11.9825 - mse: 11.9825 - val_loss: 156.1126 - val_mse: 156.1126\n",
      "Epoch 105/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 13.3133 - mse: 13.3133 - val_loss: 154.0469 - val_mse: 154.0469\n",
      "Epoch 106/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 12.0445 - mse: 12.0445 - val_loss: 161.7600 - val_mse: 161.7599\n",
      "Epoch 107/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 13.3974 - mse: 13.3974 - val_loss: 150.3726 - val_mse: 150.3726\n",
      "Epoch 108/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 8.6547 - mse: 8.6547 - val_loss: 174.0173 - val_mse: 174.0173\n",
      "Epoch 109/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 12.3997 - mse: 12.3997 - val_loss: 156.3163 - val_mse: 156.3163\n",
      "Epoch 110/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 11.6154 - mse: 11.6154 - val_loss: 143.0112 - val_mse: 143.0112\n",
      "Epoch 111/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4489/4489 [==============================] - 0s 97us/sample - loss: 27.2183 - mse: 27.2183 - val_loss: 147.0402 - val_mse: 147.0402\n",
      "Epoch 112/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 17.9944 - mse: 17.9944 - val_loss: 158.0296 - val_mse: 158.0296\n",
      "Epoch 113/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 13.2623 - mse: 13.2623 - val_loss: 141.8335 - val_mse: 141.8336\n",
      "Epoch 114/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 10.0325 - mse: 10.0325 - val_loss: 157.9731 - val_mse: 157.9730\n",
      "Epoch 115/10000\n",
      "4489/4489 [==============================] - 0s 97us/sample - loss: 13.6800 - mse: 13.6800 - val_loss: 138.8596 - val_mse: 138.8596\n",
      "Epoch 116/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 8.5500 - mse: 8.5500 - val_loss: 146.5641 - val_mse: 146.5640\n",
      "Epoch 117/10000\n",
      "4489/4489 [==============================] - 0s 97us/sample - loss: 8.9903 - mse: 8.9903 - val_loss: 153.6999 - val_mse: 153.6999\n",
      "Epoch 118/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 12.6868 - mse: 12.6868 - val_loss: 169.8311 - val_mse: 169.8311\n",
      "Epoch 119/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 15.0262 - mse: 15.0262 - val_loss: 166.9775 - val_mse: 166.9775\n",
      "Epoch 120/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 18.9925 - mse: 18.9925 - val_loss: 157.1126 - val_mse: 157.1126\n",
      "Epoch 121/10000\n",
      "4489/4489 [==============================] - 1s 118us/sample - loss: 12.7855 - mse: 12.7855 - val_loss: 172.7148 - val_mse: 172.7148\n",
      "Epoch 122/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 8.2942 - mse: 8.2942 - val_loss: 144.5536 - val_mse: 144.5536\n",
      "Epoch 123/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 10.2821 - mse: 10.2821 - val_loss: 164.7853 - val_mse: 164.7853\n",
      "Epoch 124/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 12.1719 - mse: 12.1719 - val_loss: 144.9122 - val_mse: 144.9122\n",
      "Epoch 125/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 7.0927 - mse: 7.0927 - val_loss: 139.9213 - val_mse: 139.9213\n",
      "Epoch 126/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 9.8735 - mse: 9.8735 - val_loss: 161.7408 - val_mse: 161.7408\n",
      "Epoch 127/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 10.1037 - mse: 10.1037 - val_loss: 152.8431 - val_mse: 152.8430\n",
      "Epoch 128/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 8.8223 - mse: 8.8223 - val_loss: 155.3547 - val_mse: 155.3547\n",
      "Epoch 129/10000\n",
      "4489/4489 [==============================] - 0s 97us/sample - loss: 9.9293 - mse: 9.9293 - val_loss: 186.1158 - val_mse: 186.1158\n",
      "Epoch 130/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 10.1726 - mse: 10.1726 - val_loss: 147.1630 - val_mse: 147.1631\n",
      "Epoch 131/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 10.7516 - mse: 10.7516 - val_loss: 164.0668 - val_mse: 164.0667\n",
      "Epoch 132/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 8.7489 - mse: 8.7489 - val_loss: 149.1078 - val_mse: 149.1078\n",
      "Epoch 133/10000\n",
      "4489/4489 [==============================] - 0s 95us/sample - loss: 8.0031 - mse: 8.0031 - val_loss: 132.3834 - val_mse: 132.3834\n",
      "Epoch 134/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 10.7221 - mse: 10.7221 - val_loss: 148.7525 - val_mse: 148.7525\n",
      "Epoch 135/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 16.2847 - mse: 16.2847 - val_loss: 169.3402 - val_mse: 169.3401\n",
      "Epoch 136/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 18.5471 - mse: 18.5471 - val_loss: 159.1537 - val_mse: 159.1537\n",
      "Epoch 137/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 6.9469 - mse: 6.9469 - val_loss: 148.0142 - val_mse: 148.0141\n",
      "Epoch 138/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 7.1384 - mse: 7.1384 - val_loss: 147.2816 - val_mse: 147.2816\n",
      "Epoch 139/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 7.0262 - mse: 7.0262 - val_loss: 154.3354 - val_mse: 154.3354\n",
      "Epoch 140/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 8.3255 - mse: 8.3255 - val_loss: 168.9250 - val_mse: 168.9250\n",
      "Epoch 141/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 16.4047 - mse: 16.4047 - val_loss: 161.3923 - val_mse: 161.3923\n",
      "Epoch 142/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 10.7774 - mse: 10.7774 - val_loss: 159.8146 - val_mse: 159.8146\n",
      "Epoch 143/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 11.4041 - mse: 11.4041 - val_loss: 174.3092 - val_mse: 174.3092\n",
      "Epoch 144/10000\n",
      "4489/4489 [==============================] - 1s 114us/sample - loss: 12.9004 - mse: 12.9004 - val_loss: 147.2829 - val_mse: 147.2829\n",
      "Epoch 145/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 6.6895 - mse: 6.6895 - val_loss: 150.2821 - val_mse: 150.2821\n",
      "Epoch 146/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 5.9793 - mse: 5.9793 - val_loss: 139.7150 - val_mse: 139.7150\n",
      "Epoch 147/10000\n",
      "4489/4489 [==============================] - 1s 130us/sample - loss: 7.3189 - mse: 7.3189 - val_loss: 154.6726 - val_mse: 154.6726\n",
      "Epoch 148/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 12.2690 - mse: 12.2690 - val_loss: 138.1377 - val_mse: 138.1377\n",
      "Epoch 149/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 5.1297 - mse: 5.1297 - val_loss: 154.4881 - val_mse: 154.4881\n",
      "Epoch 150/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 8.9585 - mse: 8.9585 - val_loss: 130.5317 - val_mse: 130.5317\n",
      "Epoch 151/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 9.0847 - mse: 9.0847 - val_loss: 147.4086 - val_mse: 147.4086\n",
      "Epoch 152/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 5.1799 - mse: 5.1799 - val_loss: 151.6822 - val_mse: 151.6822\n",
      "Epoch 153/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 8.8448 - mse: 8.8448 - val_loss: 143.1357 - val_mse: 143.1358\n",
      "Epoch 154/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 15.3741 - mse: 15.3742 - val_loss: 156.4191 - val_mse: 156.4191\n",
      "Epoch 155/10000\n",
      "4489/4489 [==============================] - 0s 104us/sample - loss: 10.7002 - mse: 10.7002 - val_loss: 169.2841 - val_mse: 169.2840\n",
      "Epoch 156/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 6.6788 - mse: 6.6788 - val_loss: 164.2894 - val_mse: 164.2894\n",
      "Epoch 157/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 7.2843 - mse: 7.2843 - val_loss: 145.3678 - val_mse: 145.3678\n",
      "Epoch 158/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 6.8666 - mse: 6.8666 - val_loss: 141.0902 - val_mse: 141.0901\n",
      "Epoch 159/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 5.3725 - mse: 5.3725 - val_loss: 154.0751 - val_mse: 154.0751\n",
      "Epoch 160/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 5.1682 - mse: 5.1682 - val_loss: 158.0814 - val_mse: 158.0815\n",
      "Epoch 161/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 12.8919 - mse: 12.8919 - val_loss: 154.6487 - val_mse: 154.6487\n",
      "Epoch 162/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 9.4059 - mse: 9.4059 - val_loss: 152.3515 - val_mse: 152.3515\n",
      "Epoch 163/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 8.8252 - mse: 8.8252 - val_loss: 148.3658 - val_mse: 148.3658\n",
      "Epoch 164/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 15.5315 - mse: 15.5315 - val_loss: 205.4288 - val_mse: 205.4288\n",
      "Epoch 165/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 8.5052 - mse: 8.5052 - val_loss: 192.6968 - val_mse: 192.6968\n",
      "Epoch 166/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 6.2135 - mse: 6.2135 - val_loss: 156.9347 - val_mse: 156.9347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/10000\n",
      "4489/4489 [==============================] - 1s 223us/sample - loss: 8.8891 - mse: 8.8891 - val_loss: 146.5553 - val_mse: 146.5553\n",
      "Epoch 168/10000\n",
      "4489/4489 [==============================] - 1s 154us/sample - loss: 6.9858 - mse: 6.9858 - val_loss: 155.0044 - val_mse: 155.0044\n",
      "Epoch 169/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 7.1805 - mse: 7.1805 - val_loss: 166.7110 - val_mse: 166.7110\n",
      "Epoch 170/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 8.6452 - mse: 8.6452 - val_loss: 153.7237 - val_mse: 153.7236\n",
      "Epoch 171/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 11.2187 - mse: 11.2187 - val_loss: 155.2209 - val_mse: 155.2209\n",
      "Epoch 172/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 8.5174 - mse: 8.5174 - val_loss: 170.6007 - val_mse: 170.6007\n",
      "Epoch 173/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 13.7795 - mse: 13.7795 - val_loss: 163.9680 - val_mse: 163.9680\n",
      "Epoch 174/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 8.2941 - mse: 8.2941 - val_loss: 156.3146 - val_mse: 156.3146\n",
      "Epoch 175/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 8.3267 - mse: 8.3267 - val_loss: 177.4645 - val_mse: 177.4645\n",
      "Epoch 176/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 8.6999 - mse: 8.6999 - val_loss: 187.0592 - val_mse: 187.0592\n",
      "Epoch 177/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 18.8820 - mse: 18.8820 - val_loss: 159.7968 - val_mse: 159.7968\n",
      "Epoch 178/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 16.0436 - mse: 16.0436 - val_loss: 152.5542 - val_mse: 152.5542\n",
      "Epoch 179/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 5.8115 - mse: 5.8115 - val_loss: 149.7288 - val_mse: 149.7288\n",
      "Epoch 180/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 3.5265 - mse: 3.5265 - val_loss: 144.5379 - val_mse: 144.5379\n",
      "Epoch 181/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 2.7600 - mse: 2.7600 - val_loss: 158.2463 - val_mse: 158.2463\n",
      "Epoch 182/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 6.9614 - mse: 6.9614 - val_loss: 150.7635 - val_mse: 150.7635\n",
      "Epoch 183/10000\n",
      "4489/4489 [==============================] - 0s 106us/sample - loss: 4.6069 - mse: 4.6069 - val_loss: 143.6367 - val_mse: 143.6367\n",
      "Epoch 184/10000\n",
      "4489/4489 [==============================] - 0s 111us/sample - loss: 10.4322 - mse: 10.4322 - val_loss: 144.0745 - val_mse: 144.0745\n",
      "Epoch 185/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 9.6231 - mse: 9.6231 - val_loss: 159.0557 - val_mse: 159.0557\n",
      "Epoch 186/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 6.8508 - mse: 6.8508 - val_loss: 153.4622 - val_mse: 153.4622\n",
      "Epoch 187/10000\n",
      "4489/4489 [==============================] - 0s 107us/sample - loss: 7.8260 - mse: 7.8260 - val_loss: 164.3273 - val_mse: 164.3273\n",
      "Epoch 188/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 13.4985 - mse: 13.4985 - val_loss: 156.0416 - val_mse: 156.0416\n",
      "Epoch 189/10000\n",
      "4489/4489 [==============================] - 1s 125us/sample - loss: 8.0697 - mse: 8.0697 - val_loss: 176.8454 - val_mse: 176.8454\n",
      "Epoch 190/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 3.8165 - mse: 3.8165 - val_loss: 147.3277 - val_mse: 147.3277\n",
      "Epoch 191/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 7.2998 - mse: 7.2998 - val_loss: 138.1840 - val_mse: 138.1840\n",
      "Epoch 192/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 5.1820 - mse: 5.1820 - val_loss: 186.6515 - val_mse: 186.6514\n",
      "Epoch 193/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 8.2850 - mse: 8.2850 - val_loss: 143.6135 - val_mse: 143.6135\n",
      "Epoch 194/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 8.1389 - mse: 8.1389 - val_loss: 160.6809 - val_mse: 160.6809\n",
      "Epoch 195/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 10.1934 - mse: 10.1933 - val_loss: 156.0623 - val_mse: 156.0623\n",
      "Epoch 196/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 8.9857 - mse: 8.9857 - val_loss: 163.9881 - val_mse: 163.9881\n",
      "Epoch 197/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 14.3393 - mse: 14.3393 - val_loss: 154.2416 - val_mse: 154.2416\n",
      "Epoch 198/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 7.5604 - mse: 7.5604 - val_loss: 156.6236 - val_mse: 156.6236\n",
      "Epoch 199/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 7.8158 - mse: 7.8158 - val_loss: 156.5612 - val_mse: 156.5612\n",
      "Epoch 200/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 9.1348 - mse: 9.1348 - val_loss: 156.5034 - val_mse: 156.5034\n",
      "Epoch 201/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 7.1312 - mse: 7.1312 - val_loss: 151.5991 - val_mse: 151.5991\n",
      "Epoch 202/10000\n",
      "4489/4489 [==============================] - 0s 106us/sample - loss: 4.2709 - mse: 4.2709 - val_loss: 153.7916 - val_mse: 153.7916\n",
      "Epoch 203/10000\n",
      "4489/4489 [==============================] - 1s 113us/sample - loss: 13.9992 - mse: 13.9992 - val_loss: 140.5526 - val_mse: 140.5526\n",
      "Epoch 204/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 6.8846 - mse: 6.8846 - val_loss: 158.5202 - val_mse: 158.5202\n",
      "Epoch 205/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 5.7078 - mse: 5.7078 - val_loss: 146.0123 - val_mse: 146.0123\n",
      "Epoch 206/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 5.8846 - mse: 5.8846 - val_loss: 146.6584 - val_mse: 146.6583\n",
      "Epoch 207/10000\n",
      "4489/4489 [==============================] - 0s 98us/sample - loss: 3.1442 - mse: 3.1442 - val_loss: 142.9171 - val_mse: 142.9171\n",
      "Epoch 208/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 3.7452 - mse: 3.7452 - val_loss: 140.8163 - val_mse: 140.8162\n",
      "Epoch 209/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 4.4380 - mse: 4.4380 - val_loss: 169.4495 - val_mse: 169.4495\n",
      "Epoch 210/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 5.3908 - mse: 5.3908 - val_loss: 170.8158 - val_mse: 170.8158\n",
      "Epoch 211/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 8.7506 - mse: 8.7506 - val_loss: 156.1453 - val_mse: 156.1452\n",
      "Epoch 212/10000\n",
      "4489/4489 [==============================] - 0s 99us/sample - loss: 5.2838 - mse: 5.2838 - val_loss: 156.2869 - val_mse: 156.2869\n",
      "Epoch 213/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 15.1952 - mse: 15.1952 - val_loss: 227.4985 - val_mse: 227.4985\n",
      "Epoch 214/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 9.0025 - mse: 9.0025 - val_loss: 152.5751 - val_mse: 152.5751\n",
      "Epoch 215/10000\n",
      "4489/4489 [==============================] - 0s 102us/sample - loss: 2.4262 - mse: 2.4262 - val_loss: 150.7692 - val_mse: 150.7693\n",
      "Epoch 216/10000\n",
      "4489/4489 [==============================] - 0s 101us/sample - loss: 2.7958 - mse: 2.7958 - val_loss: 161.8103 - val_mse: 161.8103\n",
      "Epoch 217/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 5.4796 - mse: 5.4796 - val_loss: 148.1751 - val_mse: 148.1751\n",
      "Epoch 218/10000\n",
      "4489/4489 [==============================] - 0s 105us/sample - loss: 10.3454 - mse: 10.3454 - val_loss: 155.9644 - val_mse: 155.9644\n",
      "Epoch 219/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 8.3364 - mse: 8.3364 - val_loss: 144.5112 - val_mse: 144.5112\n",
      "Epoch 220/10000\n",
      "4489/4489 [==============================] - 0s 109us/sample - loss: 7.1923 - mse: 7.1923 - val_loss: 151.4020 - val_mse: 151.4020\n",
      "Epoch 221/10000\n",
      "4489/4489 [==============================] - 0s 110us/sample - loss: 7.5655 - mse: 7.5655 - val_loss: 160.7160 - val_mse: 160.7160\n",
      "Epoch 222/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 4.7586 - mse: 4.7586 - val_loss: 166.1988 - val_mse: 166.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/10000\n",
      "4489/4489 [==============================] - 0s 103us/sample - loss: 5.9819 - mse: 5.9819 - val_loss: 168.6190 - val_mse: 168.6189\n",
      "Epoch 224/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 6.6716 - mse: 6.6716 - val_loss: 169.0451 - val_mse: 169.0451\n",
      "Epoch 225/10000\n",
      "4489/4489 [==============================] - 0s 100us/sample - loss: 11.7495 - mse: 11.7495 - val_loss: 179.4730 - val_mse: 179.4730\n",
      "Epoch 226/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 11.8449 - mse: 11.8449 - val_loss: 181.7744 - val_mse: 181.7744\n",
      "Epoch 227/10000\n",
      "4489/4489 [==============================] - 0s 96us/sample - loss: 15.5015 - mse: 15.5015 - val_loss: 177.7090 - val_mse: 177.7090\n",
      "Epoch 228/10000\n",
      "4489/4489 [==============================] - 0s 94us/sample - loss: 7.9850 - mse: 7.9850 - val_loss: 177.9735 - val_mse: 177.9734\n",
      "Epoch 229/10000\n",
      "3872/4489 [========================>.....] - ETA: 0s - loss: 6.1006 - mse: 6.1006"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_q, y_train_q, \n",
    "                    epochs=10000,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val_q,y_val_q),\n",
    "                    callbacks=[tensorboard_callback, earlystop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 5)\n",
      "(5000, 114, 5)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.reshape(y,(-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['quote'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>dist</th>\n",
       "      <th>gender</th>\n",
       "      <th>make</th>\n",
       "      <th>year</th>\n",
       "      <th>model</th>\n",
       "      <th>new_used</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>Belleville</td>\n",
       "      <td>10726</td>\n",
       "      <td>m</td>\n",
       "      <td>audi</td>\n",
       "      <td>2017</td>\n",
       "      <td>e-tron</td>\n",
       "      <td>used</td>\n",
       "      <td>352.599790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>Wood Buffalo</td>\n",
       "      <td>9401</td>\n",
       "      <td>m</td>\n",
       "      <td>toyota</td>\n",
       "      <td>2001</td>\n",
       "      <td>camry</td>\n",
       "      <td>used</td>\n",
       "      <td>1723.855245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>Kelowna</td>\n",
       "      <td>9427</td>\n",
       "      <td>m</td>\n",
       "      <td>acura</td>\n",
       "      <td>2016</td>\n",
       "      <td>mdx</td>\n",
       "      <td>used</td>\n",
       "      <td>221.792349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>St. John</td>\n",
       "      <td>21090</td>\n",
       "      <td>m</td>\n",
       "      <td>ford</td>\n",
       "      <td>2003</td>\n",
       "      <td>explorer</td>\n",
       "      <td>used</td>\n",
       "      <td>1723.855245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>Sarnia</td>\n",
       "      <td>7099</td>\n",
       "      <td>m</td>\n",
       "      <td>audi</td>\n",
       "      <td>2018</td>\n",
       "      <td>e-tron</td>\n",
       "      <td>used</td>\n",
       "      <td>354.748787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          city   dist gender    make  year     model new_used  \\\n",
       "0   61    Belleville  10726      m    audi  2017    e-tron     used   \n",
       "1   21  Wood Buffalo   9401      m  toyota  2001     camry     used   \n",
       "2   83       Kelowna   9427      m   acura  2016       mdx     used   \n",
       "3   28      St. John  21090      m    ford  2003  explorer     used   \n",
       "4   56        Sarnia   7099      m    audi  2018    e-tron     used   \n",
       "\n",
       "         quote  \n",
       "0   352.599790  \n",
       "1  1723.855245  \n",
       "2   221.792349  \n",
       "3  1723.855245  \n",
       "4   354.748787  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(data_path / file_csv[0],)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop(['quote'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 'Belleville', 10726, ..., 2017, 'e-tron', 'used'],\n",
       "       [21, 'Wood Buffalo', 9401, ..., 2001, 'camry', 'used'],\n",
       "       [83, 'Kelowna', 9427, ..., 2016, 'mdx', 'used'],\n",
       "       ...,\n",
       "       [43, 'Montreal', 2619, ..., 2003, 'corrola', 'used'],\n",
       "       [37, 'Laval', 16457, ..., 2017, 'c', 'used'],\n",
       "       [20, 'Fredericton', 14860, ..., 2015, 's', 'used']], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(df1,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>dist</th>\n",
       "      <th>year</th>\n",
       "      <th>quote</th>\n",
       "      <th>city_Airdrie</th>\n",
       "      <th>city_Ajax</th>\n",
       "      <th>city_Aurora</th>\n",
       "      <th>city_Barrie</th>\n",
       "      <th>city_Belleville</th>\n",
       "      <th>city_Blainville</th>\n",
       "      <th>...</th>\n",
       "      <th>model_mirano</th>\n",
       "      <th>model_r8</th>\n",
       "      <th>model_rsx</th>\n",
       "      <th>model_s</th>\n",
       "      <th>model_sierra</th>\n",
       "      <th>model_terrain</th>\n",
       "      <th>model_x</th>\n",
       "      <th>model_x5</th>\n",
       "      <th>model_yukon</th>\n",
       "      <th>new_used_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>10726</td>\n",
       "      <td>2017</td>\n",
       "      <td>352.599790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9401</td>\n",
       "      <td>2001</td>\n",
       "      <td>1723.855245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>9427</td>\n",
       "      <td>2016</td>\n",
       "      <td>221.792349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>21090</td>\n",
       "      <td>2003</td>\n",
       "      <td>1723.855245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>7099</td>\n",
       "      <td>2018</td>\n",
       "      <td>354.748787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   dist  year        quote  city_Airdrie  city_Ajax  city_Aurora  \\\n",
       "0   61  10726  2017   352.599790             0          0            0   \n",
       "1   21   9401  2001  1723.855245             0          0            0   \n",
       "2   83   9427  2016   221.792349             0          0            0   \n",
       "3   28  21090  2003  1723.855245             0          0            0   \n",
       "4   56   7099  2018   354.748787             0          0            0   \n",
       "\n",
       "   city_Barrie  city_Belleville  city_Blainville  ...  model_mirano  model_r8  \\\n",
       "0            0                1                0  ...             0         0   \n",
       "1            0                0                0  ...             0         0   \n",
       "2            0                0                0  ...             0         0   \n",
       "3            0                0                0  ...             0         0   \n",
       "4            0                0                0  ...             0         0   \n",
       "\n",
       "   model_rsx  model_s  model_sierra  model_terrain  model_x  model_x5  \\\n",
       "0          0        0             0              0        0         0   \n",
       "1          0        0             0              0        0         0   \n",
       "2          0        0             0              0        0         0   \n",
       "3          0        0             0              0        0         0   \n",
       "4          0        0             0              0        0         0   \n",
       "\n",
       "   model_yukon  new_used_used  \n",
       "0            0              1  \n",
       "1            0              1  \n",
       "2            0              1  \n",
       "3            0              1  \n",
       "4            0              1  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 140)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df1.to_numpy()\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
